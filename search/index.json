[{"content":" 由于之前博客为了输入方便一直放在根域名，现在需要将字体部署到子域名下，为了干净整洁些需要将之前的DNS删除。\n并且不再用vercel部署，采用cloudflare\n进入cloudflare，添加一个编辑区域DNS的API Token，并记录下Token。\n点击进入域名的概述，Zone ID在右侧一列中\n创建一个powershell脚本(.ps1)，并替换API_TOKEN和ZONE_ID\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 $API_TOKEN = \u0026#34;\u0026lt;API_TOKEN\u0026gt;\u0026#34; $ZONE_ID = \u0026#34;\u0026lt;ZONE_ID\u0026gt;\u0026#34; $baseUrl = \u0026#34;https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dns_records\u0026#34; $headers = @{ \u0026#39;Authorization\u0026#39; = \u0026#34;Bearer $API_TOKEN\u0026#34; \u0026#39;Content-Type\u0026#39; = \u0026#34;application/json\u0026#34; } $listUrl = $baseUrl + \u0026#39;?per_page=500\u0026#39; Write-Host $listUrl $records = Invoke-RestMethod -Uri $listUrl -Method \u0026#39;GET\u0026#39; -Headers $headers $records = $records | Select-Object -ExpandProperty result foreach ($record in $records) { Write-Host \u0026#34;Deleting $($record.name) that points to $($record.content)\u0026#34; $deleteUrl = $baseUrl + \u0026#39;/\u0026#39; + $record.id Invoke-RestMethod -Uri $deleteUrl -Method \u0026#39;DELETE\u0026#39; -Headers $headers Write-Host $deleteUrl } 右键文件以powershell运行。由于我有700多条记录，执行两次即可\n好有副岛成记的风格\n@Chuzenji\n参考 cover:@mocha\nBulk delete DNS records\n","date":"2023-10-19T16:35:44+08:00","image":"/post/cloudflare-dns-delete/cover.jpg","permalink":"/post/cloudflare-dns-delete/","title":"Cloudflare Dns 批量删除"},{"content":"前言 我创建这个博客的初衷，有很大一部分是方便记录分享自己实现的一些几何节点效果，因此写一下这篇文章来分享一下我之前学习过程中的一些感悟和经验，希望对你有帮助。\n感兴趣的话可以看下我的Artstation或者Bilibili，里面大概还是有很多相关的内容的，或者你也可以打开Gumroad直接下载去玩玩看。\n随便举两个例子\n用途 我们之所以用几何节点制作效果当然是因为它有很多好处。程序化节点式的工作流让你能够轻松快捷地调整最终效果，而不是又从零到一地画一幅画，并且我们能精确地操控每一个参数供我们使用。也能够将工作流中常使用的效果打包为节点组，高效地嵌套使用。\n学习方法 其实最快的学习方式就是看到一个好看的效果，直接上手去实现。做的过程中会慢慢地了解制作思路，遇到理解不了的节点就去翻翻文档或解释的视频。\n国内的话强烈建议可以看看峰峰居士和darkstarrd的视频，之后尤其要了解一下几何节点中的几何流和函数流思想。\n至于版本我建议使用3.4之后的版本，很多冗余的节点都被修改了，3.3也行，大差不差。\n其实最重要的是多看别人开阔眼界，过程中了解一些自己之前没怎么用到的节点和思路。看到一个大佬的推文或教程之后，根据相关推荐发现一个又一个新大陆。入门之后可以尝试用各种节点包加速工作流，我了解到的部分内容放在相关资源里。\n必要插件 内置插件Node Wrangler，有点基础的话应该都开启了，善用Ctrl Shift LMB预览值和其他基础操作\nnode_tabber，使用houdini的方式搜索节点。对我来说相当重要的插件，再用不用Shift A多点几步了，拯救时间的利器\n效果如下，快速查找节点\n相关资源 推荐博主\n入门\nJoey Carlino Sina Sinaie CrossmindStudio Johnny Matthews Khamurai 进阶\nCartesian Caramel Celestialmaze Erindale HotdogNugget Toolkit\nBradley Node Preset Erindale Toolkit Higgsas Nodes 结语 总之在学习中开拓自己的思路是最重要的，没有几何节点实现不了的效果，创意是无限的\nLily\u0026amp;Buttercups\n参考与鸣谢 cover: @Dino\n","date":"2023-10-05T23:20:26+08:00","image":"/post/geometrynode-start/cover.jpg","permalink":"/post/geometrynode-start/","title":"几何节点入门纲要"},{"content":"前言 上个月从零开始直接上手react three fiber，跟着同事写了一堆交互，总算弄得差不多了。不会React，不会TS，不会three，真不知道自己怎么过来的。途中也了解到原子化css，总之收获颇丰。目前是因为需要将渲染画面推流到场景中，故做点经验分享\n前期准备 首先得创建个场景然后播放视频吧，可以参考下面我做的这个案例\nGreenScreen-Streaming\n首先做一个VideoMaterial的function，减少耦合度。当然你也可以写的简单点，这里主要是为了后续添加遮罩的方便。但是存在一定色差，暂时没找到解决方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 function VideoMaterial({ src, mask_src }) { const texture = src ? useVideoTexture(src) : null const mask = mask_src ? useVideoTexture(mask_src) : null return ( \u0026lt;meshPhysicalMaterial color={0x000000} emissive={0xffffff} emissiveMap={texture} alphaMap={mask} emissiveIntensity={1} opacity={1} transparent={true} toneMapped={false} /\u0026gt; ); } 记得用Suspense包裹一下，不然会报错,因为渲染的前后关系不对。建议fallback里给个材质留给加载的时间，这里我放了个loading的动画\n1 2 3 4 5 6 7 8 9 \u0026lt;mesh\u0026gt; \u0026lt;planeGeometry args={[7.111, 4]} /\u0026gt; \u0026lt;Suspense fallback={\u0026lt;VideoMaterial src=\u0026#34;loading.mp4\u0026#34; /\u0026gt;}\u0026gt; \u0026lt;Suspense \u0026gt; \u0026lt;VideoMaterial src=\u0026#34;WING IT! - Blender Open Movie.mp4\u0026#34; mask_src=\u0026#39;mask.mp4\u0026#39; /\u0026gt; \u0026lt;/Suspense\u0026gt; \u0026lt;/mesh\u0026gt; 这样就可以看到一个带透明通道的视频显示在屏幕上，当然可能用quicktime格式会更快些，但体积大\n视频流 有条件的可以现在主机上插个摄像头，先通过API获取到视频流\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 const [stream, setStream] = useState() useEffect(async () =\u0026gt; { const constraints = { audio: false, video: true, } navigator.mediaDevices .getUserMedia(constraints) .then((stream) =\u0026gt; { window.stream = stream setStream(stream) console.log(stream) navigator.mediaDevices.enumerateDevices().then(function (devices) {console.log(devices)}) }) .catch((error) =\u0026gt; { console.log(error) }) }, []) 不出意外的话屏幕上就能出现摄像头的画面了。另外可以在useState中设置参数来显示加载动画\nOBS虚拟摄像头 但是我们如果想输出各种画面一般都是使用OBS的虚拟摄像机推流。那么怎么切换摄像机呢？\n可以看到上述的代码通过使用constraints来约束使用的摄像头，需要的deviceId可从console中获取\n1 2 3 4 5 InputDeviceInfo deviceId: \u0026#34;6bd3a42e2bf68c2246a5a9bcffa2e43fab316554f504a6ad5687c5674ea6e5d1\u0026#34; groupId: \u0026#34;e8291660abbb766dfaaebafbd6f4d3eb046f00603e3cb4d3c2bcd30673415982\u0026#34; kind: \u0026#34;videoinput\u0026#34; label: \u0026#34;OBS Virtual Camera\u0026#34; 于是我们找到OBS虚拟摄像头的信息,填入constraints\n1 2 3 4 5 6 7 const constraints = { audio: true, video: { deviceId: \u0026lt;YOUR OBS ID\u0026gt; } } 绿幕shader 接下来就剩抠绿幕了。你或许会问为什么不在OBS里直接用色度键去除呢？因为它不支持推流视频带alpha通道，虽然抠的只剩个人但推出去还是个大黑框\n于是我们就得用到shaderMaterial\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 const vertexShader = ` varying vec2 vUv; void main( void ) { vUv = uv; gl_Position = projectionMatrix * modelViewMatrix * vec4(position,1.0); } ` export default vertexShader; const fragmentShader = ` uniform vec3 keyColor; uniform float similarity; uniform float smoothness; varying vec2 vUv; uniform sampler2D map; void main() { vec4 videoColor = texture2D(map, vUv); float Y1 = 0.299 * keyColor.r + 0.587 * keyColor.g + 0.114 * keyColor.b; float Cr1 = keyColor.r - Y1; float Cb1 = keyColor.b - Y1; float Y2 = 0.299 * videoColor.r + 0.587 * videoColor.g + 0.114 * videoColor.b; float Cr2 = videoColor.r - Y2; float Cb2 = videoColor.b - Y2; float blend = smoothstep(similarity, similarity + smoothness, distance(vec2(Cr2, Cb2), vec2(Cr1, Cb1))); gl_FragColor = vec4(videoColor.rgb, videoColor.a * blend); } ` export default fragmentShader App.js内\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 const streamTexture = useVideoTexture(stream); const material = new THREE.ShaderMaterial({ transparent: true, uniforms: { map: { value: streamTexture }, keyColor: { value: [0.0, 1.0, 0.0] }, similarity: { value: 0.7 }, smoothness: { value: 0.0 } }, vertexShader, fragmentShader }); return ( \u0026lt;Suspense\u0026gt; \u0026lt;mesh position={[-8, 2, -4]} scale={1} material={material} \u0026gt; \u0026lt;planeGeometry args={[7.111, 4]} /\u0026gt; \u0026lt;/mesh\u0026gt; \u0026lt;/Suspense\u0026gt; ); 这里我事先放了一个绿幕视频作为加载动画，只要输入自己的deviceId就能正常显示了\n后话 至于为什么这里不采用VideoMaterial另开一个材质函数的写法，而是three.js的用法，是因为我也不知道为什么会有bug，欢迎在评论区交流\n最后在实际体验过程中，我需要让这块平面始终朝向摄像机，会的人可能觉得一个useRef和useFrame就解决了，但是我拿不到父组件的摄像头信息。后来终于发现可以用useThree这个hook，直接拿到camera\n参考链接 webcam\nBye~Bye 和纱太好看了\n@Kerno_kr\n","date":"2023-09-14T17:18:38+08:00","image":"/post/r3f-streaming/cover.jpg","permalink":"/post/r3f-streaming/","title":"R3F蒙版\u0026绿幕推流"},{"content":"研究了一会儿hugo中怎样使用图片，顺便做个记录。\n最高效正确的方法应该就是使用Markdown render hooks，即可通过以下的markdown形式快速地调整图片大小\n1 2 3 4 5 6 7 ![Petrified Forest](a.jpg?w=500) ![Bryce Canyon](images/b.jpg?h=200\u0026amp;f=webp) ![Zion](images/c.jpg?w=150\u0026amp;h=150\u0026amp;m=fill\u0026amp;q=50\u0026amp;f=png\u0026amp;i=my-id\u0026amp;c=my-class) ![Hugo logo](https://gohugo.io/img/hugo-logo.png?w=200) 但是我太懒还没学会，最简单的应该就是用html自带的img标签，但不知道为什么我这无法显示，如果这样的话我目前发现有两种解决办法\n在theme的css中添加需要的样式，我使用的papermod主题默认在post-single文件中\n1 2 3 4 5 6 7 .post-content img[src*=\u0026#34;#minipic\u0026#34;] { max-width: 200px; display: block; } //使用 ![a](../1.png#minipic) 也可以把标签加在alt中，但这样局限性很大，最多定义几种常用大小。\n另外一种方法就是使用shortcodes，类似于组件，官方已经写好了一个figure\n1 {{去掉#\u0026lt; figure src=\u0026#34;../1.png#center\u0026#34; width=250px \u0026gt;}} 除此之外还有的需求尤其是移动端就是要能够放大图片，于是我在这个issue下找到了答案\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # render-image.html {{- if and (ne .Page.Kind \u0026#34;section\u0026#34;) (.Page.Section ) }} \u0026lt;!-- Generate a unique id for each image --\u0026gt; {{- $random := (substr (md5 .Destination) 0 5) }} \u0026lt;input type=\u0026#34;checkbox\u0026#34; id=\u0026#34;zoomCheck-{{$random}}\u0026#34; hidden\u0026gt; \u0026lt;label for=\u0026#34;zoomCheck-{{$random}}\u0026#34;\u0026gt; \u0026lt;img class=\u0026#34;zoomCheck\u0026#34; loading=\u0026#34;lazy\u0026#34; decoding=\u0026#34;async\u0026#34; src=\u0026#34;{{ .Destination | safeURL }}\u0026#34; alt=\u0026#34;{{ .Text }}\u0026#34; {{ with.Title}} title=\u0026#34;{{ . }}\u0026#34; {{ end }} /\u0026gt; \u0026lt;/label\u0026gt; {{- else }} \u0026lt;img loading=\u0026#34;lazy\u0026#34; decoding=\u0026#34;async\u0026#34; src=\u0026#34;{{ .Destination | safeURL }}\u0026#34; alt=\u0026#34;{{ .Text }}\u0026#34; {{ with .Title}} title=\u0026#34;{{ . }}\u0026#34; {{ end }} /\u0026gt; {{- end }} # extend_footer.html \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js\u0026#34; integrity=\u0026#34;sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; referrerpolicy=\u0026#34;no-referrer\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; const images = Array.from(document.querySelectorAll(\u0026#34;.post-content img\u0026#34;)); images.forEach(img =\u0026gt; { mediumZoom(img, { margin: 20, /* The space outside the zoomed image */ scrollOffset: 40, /* The number of pixels to scroll to close the zoom */ container: null, /* The viewport to render the zoom in */ template: null, /* The template element to display on zoom */ background: \u0026#39;rgba(0, 0, 0, 0.8)\u0026#39; }); }); \u0026lt;/script\u0026gt; \u0026lt;!-- https://ionic.io/ionicons --\u0026gt; \u0026lt;script type=\u0026#34;module\u0026#34; src=\u0026#34;https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script nomodule src=\u0026#34;https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 在以上两个文件中添加代码后就可以愉快缩放了，剩下的效果自由发挥。\n目前我更换主题后，要看具体情况更改（比如主题自带对image的处理），querySelectorAll后的内容可通过F12定位css的具体位置。\n突然想看排球了\n@96yottea\n","date":"2023-08-20T23:03:03+08:00","image":"/post/hugo-image/cover.jpg","permalink":"/post/hugo-image/","title":"Hugo中使用图片的一些心得"},{"content":"其实很早就想搭一个技术博客了，但是一直感觉无从弄起而且耗费精力，直到我看到了Cyanilux这个网站，了解到了hugo，况且我也刚组了台主机，就将这作为纪念吧。\n配置方面我觉得已经完全够用好多年了，颜值也是无比的高，就是用着这堪堪50%cuda数量的4080有些许难受。原先有考虑尝试背插方案，但由于兼容的主板和机箱太少，最后放弃了。\n虽然是第一次装机，但是现在互联网上优质的教程太多了，完全可以自给自足，强烈推荐硬件茶谈或者装机猿的相声。\n说实话看视频是一点不难，但是实际上手会多出一堆需要考虑的问题，尤其是走线之类的。我第一次就把散热器装歪了90度，还有一堆ARGB风扇的连接线，直接把我猪脑烧过载了😅本来用的是送的三个风扇，结果由于没集线器和线缆长度问题，后来搞了3个乔思伯积木风扇，是真的方便。\n实际操作时，插那个CPU的供电线简直反人类，主板24pin供电尽量一次怼进去。至于理线那又是一个痛苦折磨的过程，我这没旋转桌子，趴在地上前后翻腾了一下午，腰酸背痛。\n之后就是把显卡插进去，哎呦那个槽是真难对准。满心欢喜地开机，所有东西都在转，结果第一次居然显示屏不亮，我折腾了半天都没有成功，在床上躺到三点实在睡不着，再爬起来试试。由于我装了fc140的散热器，内存条是被挡住的挺麻烦，最后果然是内存条没插紧，两侧合上的卡扣欺骗了我😭。最后终于进BIOS了\n刚开始识别不到固态也奇了怪了，总之之后就是装系统，我是用了rufus来装，之前steamdeck用过就继续用了。当然可能PE更方便实用些。\n最后就是装各种驱动，无尽地迁移工程、安装软件了。Valorant能稳定5、600帧实在太爽啦\n纪念这历史性的一刻\n感恩父母 后记 前几天由于windows擅自更新的缘故，后来直接无限进入自动修复的重启界面，还原点没用、卸载更新没用，连插u盘进PE系统都蓝屏，最后无奈重装系统。\n一定要禁用更新啊 @Dino_illus\n","date":"2023-08-13T22:19:17+08:00","image":"/post/my-first-post/cover.jpg","permalink":"/post/my-first-post/","title":"年轻人的第一台主机"}]